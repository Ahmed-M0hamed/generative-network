{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb709ff",
   "metadata": {},
   "source": [
    "# ACGAN => Auxiliary Classifier gan \n",
    "### this network is similar to the CGAN but instead of passing one hot label vector to both generator and discriminator we just pass it to the generator and give the discriminator another classification task to preform we will make the model classify the output and this belived to make the network learn better so we used this architecture \n",
    "\n",
    "![ACGAN](images/ACGAN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ae7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "from tensorflow.keras.layers import Dense , Conv2D ,concatenate, Conv2DTranspose , Flatten , Reshape  , BatchNormalization , Activation, Flatten ,LeakyReLU\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import mnist \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import math \n",
    "import os \n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d798a",
   "metadata": {},
   "source": [
    "# Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774c7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model) : \n",
    "    def __init__(self) : \n",
    "        super().__init__()  \n",
    "        self.dense_1 = Dense(7*7*128 ) \n",
    "        self.reshape = Reshape((7,7,128))\n",
    "\n",
    "        \n",
    "        self.sequential = Sequential([\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') , \n",
    "             Conv2DTranspose(128 , 5 , strides = 2 , padding = 'same') , \n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(64 , 5 , strides = 2  , padding = 'same') ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(32 , 5   , padding = 'same') ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(1 , 5  , padding = 'same') , \n",
    "             Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "    def call(self , inputs ) :\n",
    "        X_vector , one_hot_vector = inputs\n",
    "        X = concatenate([X_vector , one_hot_vector] , axis = 1) \n",
    "        X = self.reshape(self.dense_1(X ))\n",
    "        return self.sequential(X)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fc3ec",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08330dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model) : \n",
    "    def __init__(self) : \n",
    "        super().__init__() \n",
    "        self.sequential = Sequential([\n",
    "            LeakyReLU(.2), \n",
    "            Conv2D(32 , 5 , padding ='same' , strides = 2) , \n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(64 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(128 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(256 , 5 , padding ='same'  ) ,\n",
    "            Flatten() , \n",
    "        ])\n",
    "        self.output_1 = Dense(1 , activation ='sigmoid') \n",
    "        self.output_2 = Dense(10 , activation ='softmax' )\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def call(self, inputs ) : \n",
    "        X =  self.sequential(inputs) \n",
    "        output_1 = self.output_1(X) \n",
    "        output_2 = self.output_2(X) \n",
    "        return output_1 , output_2 \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a427131",
   "metadata": {},
   "source": [
    "# Adversarial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fe39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversarial(tf.keras.Model) : \n",
    "    def __init__(self , generator , discriminator) : \n",
    "        super().__init__()\n",
    "        self.generator = generator \n",
    "        self.discriminator = discriminator\n",
    "        \n",
    "    def call(self , inputs ) : \n",
    "        noise , labels = inputs \n",
    "        images = self.generator((noise , labels)) \n",
    "        return self.discriminator( images ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c8cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models , data , params ) : \n",
    "\n",
    "\n",
    "    generator, discriminator, adversarial = models\n",
    "    x_train, y_train = data\n",
    "    batch_size, latent_size, train_steps, num_labels, model_name = params\n",
    "    save_interval = 500\n",
    "\n",
    "    # noise vector to see how the generator output evolves during training\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "    # one-hot label the noise will be conditioned to\n",
    "    noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n",
    "    # number of elements in train dataset\n",
    "    train_size = x_train.shape[0]\n",
    "    \n",
    "    for i in range(train_steps ) : \n",
    "\n",
    "        ##### train the discriminator for 1 batch\n",
    "\n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "        # corresponding one-hot labels of real images\n",
    "        real_labels = y_train[rand_indexes]\n",
    "        # generate fake images from noise using generator\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # assign random one-hot labels\n",
    "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
    "                                                          batch_size)]\n",
    "\n",
    "        # generate fake images conditioned on fake labels\n",
    "        fake_images = generator.predict((noise, fake_labels))\n",
    "        # real + fake images = 1 batch of train data\n",
    "        x = np.concatenate((real_images, fake_images))\n",
    "        # real + fake one-hot labels = 1 batch of train one-hot labels\n",
    "        labels = np.concatenate((real_labels, fake_labels))\n",
    "\n",
    "        # label real and fake images\n",
    "        # real images label is 1.0\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        # fake images label is 0.0\n",
    "        y[batch_size:, :] = 0.0\n",
    "        # train discriminator network, log the loss and accuracy\n",
    "        metrics = discriminator.train_on_batch(x , [y , labels ])\n",
    "        fmt = \"%d: [disc loss: %f, srcloss: %f,\" \n",
    "        fmt += \"lblloss: %f, srcacc: %f, lblacc: %f]\" \n",
    "        log = fmt % (i, metrics[0], metrics[1], \\\n",
    "                metrics[2], metrics[3], metrics[4])\n",
    "\n",
    "        ###### train the adversarial network for 1 batch\n",
    "\n",
    "        # generate noise using uniform distribution        \n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # assign random one-hot labels\n",
    "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
    "                                                          batch_size)]\n",
    "        # label fake images as real or 1.0\n",
    "        y = np.ones([batch_size, 1])\n",
    "        # train the adversarial network \n",
    "        metrics = adversarial.train_on_batch((noise, fake_labels), [y , fake_labels]) \n",
    "        fmt = \"%s [advr loss: %f, srcloss: %f,\"\n",
    "        fmt += \"lblloss: %f, srcacc: %f, lblacc: %f]\" \n",
    "        log = fmt % (log, metrics[0], metrics[1],\\\n",
    "                metrics[2], metrics[3], metrics[4])\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            # plot generator images on a periodic basis\n",
    "            print(log)\n",
    "            plot_images(generator,\n",
    "                        noise_input=noise_input,\n",
    "                        noise_class=noise_class,\n",
    "                        show=False,\n",
    "                        step=(i + 1),\n",
    "                        model_name=model_name)\n",
    "    \n",
    "    # save the model after training the generator\n",
    "    # the trained generator can be reloaded for \n",
    "    # future MNIST digit generation\n",
    "    generator.save(model_name + \".h5\")\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,\n",
    "                noise_input,\n",
    "                noise_class,\n",
    "                show=False,\n",
    "                step=0,\n",
    "                model_name=\"gan\"):\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict([noise_input, noise_class])\n",
    "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd255bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models():\n",
    "\n",
    "    # load MNIST dataset\n",
    "    (x_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    image_size = x_train.shape[1]\n",
    "    x_train = np.reshape(x_train, \n",
    "                         [-1, image_size, image_size, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "\n",
    "    # train labels\n",
    "    num_labels = len(np.unique(y_train))\n",
    "    y_train = to_categorical(y_train)\n",
    "\n",
    "    model_name = \"acgan_mnist\"\n",
    "    # network parameters\n",
    "    latent_size = 100\n",
    "    batch_size = 64\n",
    "    train_steps = 40000\n",
    "    lr = 2e-4\n",
    "    decay = 6e-8\n",
    "    \n",
    "    # call discriminator builder \n",
    "    # with 2 outputs, pred source and labels\n",
    "    discriminator = Discriminator()\n",
    "    # [1] uses Adam, but discriminator \n",
    "    # easily converges with RMSprop\n",
    "    optimizer = RMSprop(lr=lr, decay=decay)\n",
    "    # 2 loss fuctions: 1) probability image is real\n",
    "    # 2) class label of the image\n",
    "    loss = ['binary_crossentropy', 'categorical_crossentropy']\n",
    "    discriminator.compile(loss=loss,\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # build generator model\n",
    "    # call generator builder with input labels\n",
    "    generator = Generator()\n",
    "\n",
    "    # build adversarial model = generator + discriminator\n",
    "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
    "    # freeze the weights of discriminator \n",
    "    # during adversarial training\n",
    "    discriminator.trainable = False\n",
    "    adversarial = Adversarial(generator , discriminator)\n",
    "    # same 2 loss fuctions: 1) probability image is real\n",
    "    # 2) class label of the image\n",
    "    adversarial.compile(loss=loss,\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "    # train discriminator and adversarial networks\n",
    "    models = (generator, discriminator, adversarial)\n",
    "    data = (x_train, y_train)\n",
    "    params = (batch_size, latent_size, \\\n",
    "             train_steps, num_labels, model_name)\n",
    "    train(models, data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea532f50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuild_and_train_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mbuild_and_train_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# train labels\u001b[39;00m\n\u001b[1;32m     16\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train))\n\u001b[0;32m---> 17\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m(y_train)\n\u001b[1;32m     19\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macgan_mnist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# network parameters\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "build_and_train_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

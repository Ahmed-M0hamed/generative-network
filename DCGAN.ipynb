{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6120f93c",
   "metadata": {},
   "source": [
    "# DCGAN \n",
    "###  this network is the same architecture as gans but with some enhancements and changes so I followed this architecture \n",
    "\n",
    "![DCGAN](images/DCGAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb772a6e",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba828ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "from tensorflow.keras.layers import Dense , Conv2D , Conv2DTranspose , Flatten , Reshape  , BatchNormalization , Activation, Flatten ,LeakyReLU\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import mnist \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import  math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245d89a",
   "metadata": {},
   "source": [
    "# generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d9bb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model) : \n",
    "    def __init__(self  ) : \n",
    "        super().__init__() \n",
    "        self.dense_1 = Dense(7*7*128 ) \n",
    "        self.reshape = Reshape((7,7,128))\n",
    "\n",
    "    \n",
    "        self.sequential = Sequential([\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') , \n",
    "             Conv2DTranspose(128 , 5 , strides = 2 , padding = 'same' , use_bias=False) , \n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(64 , 5 , strides = 2  , padding = 'same' , use_bias=False) ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(32 , 5   , padding = 'same' , use_bias=False) ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(1 , 5  , padding = 'same' , use_bias=False) , \n",
    "             Activation('sigmoid')\n",
    "        ])\n",
    "    def call(self,  X ) : \n",
    "        X = self.reshape(self.dense_1(X))\n",
    "        X = self.sequential(X)\n",
    "        return  X "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9f1d0",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fcf50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model) : \n",
    "    def __init__(self ) : \n",
    "        super().__init__() \n",
    "        self.sequential = Sequential([\n",
    "            LeakyReLU(.2), \n",
    "            Conv2D(32 , 5 , padding ='same' , strides = 2) , \n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(64 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(128 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(256 , 5 , padding ='same'  ) ,\n",
    "            Flatten() , \n",
    "            Dense(1) , \n",
    "            Activation('sigmoid') \n",
    "        ])\n",
    "    def call(self, X) : \n",
    "        return self.sequential(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf8c43",
   "metadata": {},
   "source": [
    "# training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "314087d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images , generator , discriminator  , loss_fn , gen_optimizer , dis_optimizer):\n",
    "    noise = tf.random.normal([64, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = loss_fn(fake_output , tf.ones_like(fake_output))\n",
    "        disc_real_loss = loss_fn(real_output, tf.ones_like(real_output)) \n",
    "        disc_fake_loss = loss_fn(fake_output , tf.zeros_like(fake_output))\n",
    "        disc_loss = disc_real_loss + disc_fake_loss\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,\n",
    "                noise_input,\n",
    "                show=False,\n",
    "                step=0,\n",
    "                model_name=\"gan\"):\n",
    "    \n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict(noise_input)\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aada51",
   "metadata": {},
   "source": [
    "# build the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "999b1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models(epochs):\n",
    "    # load MNIST dataset\n",
    "    (x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    x_train = np.reshape(x_train, [-1, 28, 28, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices(x_train ) \n",
    "    ds = ds.shuffle(60000).batch(64)\n",
    "\n",
    "\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    # build discriminator model\n",
    "    discriminator = Discriminator()\n",
    "    # build generator model\n",
    "    generator = Generator()\n",
    "    \n",
    "    for epoch in range(epochs) : \n",
    "        for batch in ds : \n",
    "            train_step(images = batch , generator = generator  , discriminator = discriminator\n",
    "            , loss_fn =cross_entropy , gen_optimizer = generator_optimizer , dis_optimizer =discriminator_optimizer )\n",
    "\n",
    "        plot_images(generator ,tf.random.normal([16, 100]) , step = epoch  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f87e1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:01:22.131096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "build_and_train_models(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab728a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

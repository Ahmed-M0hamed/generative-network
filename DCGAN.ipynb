{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6120f93c",
   "metadata": {},
   "source": [
    "# DCGAN \n",
    "###  this network is the same architecture as gans but with some enhancements and changes so I followed this architecture \n",
    "\n",
    "![DCGAN](images/DCGAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb772a6e",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba828ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "from tensorflow.keras.layers import Dense , Conv2D , Conv2DTranspose , Flatten , Reshape  , BatchNormalization , Activation, Flatten ,LeakyReLU\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import mnist \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245d89a",
   "metadata": {},
   "source": [
    "# generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model) : \n",
    "    def __init__(self  ) : \n",
    "        super().__init__() \n",
    "        self.dense_1 = Dense(7*7*128 ) \n",
    "        self.reshape = Reshape((7,7,128))\n",
    "\n",
    "    \n",
    "        self.sequential = Sequential([\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') , \n",
    "             Conv2DTranspose(128 , 5 , strides = 2 , padding = 'same') , \n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(64 , 5 , strides = 2  , padding = 'same') ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(32 , 5   , padding = 'same') ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(1 , 5  , padding = 'same') , \n",
    "             Activation('sigmoid')\n",
    "        ])\n",
    "    def call(self,  X ) : \n",
    "        X = self.reshape(self.dense_1(X))\n",
    "        X = self.sequential(X)\n",
    "        return  X "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9f1d0",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf50d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model) : \n",
    "    def __init__(self ) : \n",
    "        super().__init__() \n",
    "        self.sequential = Sequential([\n",
    "            LeakyReLU(.2), \n",
    "            Conv2D(32 , 5 , padding ='same' , strides = 2) , \n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(64 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(128 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(256 , 5 , padding ='same'  ) ,\n",
    "            Flatten() , \n",
    "            Dense(1) , \n",
    "            Activation('sigmoid') \n",
    "        ])\n",
    "    def call(self, X) : \n",
    "        return self.sequential(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf8c43",
   "metadata": {},
   "source": [
    "# training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314087d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, x_train, params):\n",
    "\n",
    "    generator, discriminator, adversarial = models\n",
    "    batch_size, latent_size, train_steps, model_name = params\n",
    "    save_interval = 500\n",
    "    # noise vector to see how the generator output evolves during training\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "    # number of elements in train dataset\n",
    "    train_size = x_train.shape[0]\n",
    "    for i in range(train_steps):\n",
    "\n",
    "        # select random batch of data \n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "\n",
    "        ###### train discriminator  \n",
    "        \n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # generate fake images\n",
    "        fake_images = generator.predict(noise)\n",
    "        # real + fake images = 1 batch of train data\n",
    "        x = np.concatenate((real_images, fake_images))\n",
    "        # label real and fake images\n",
    "        # real images label is 1.0\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        # fake images label is 0.0\n",
    "        y[batch_size:, :] = 0.0\n",
    "        # train discriminator network, log the loss and accuracy\n",
    "        loss, acc = discriminator.train_on_batch(x, y)\n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "\n",
    "\n",
    "        ######## train the adversarial network for 1 batch\n",
    "        # 1 batch of fake images with label=1.0\n",
    "        # since the discriminator weights are frozen in adversarial network\n",
    "        # only the generator is trained\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0, \n",
    "                                  size=[batch_size, latent_size])\n",
    "        # label fake images as real or 1.0\n",
    "        y = np.ones([batch_size, 1])\n",
    "        # train the adversarial network \n",
    "        # note that unlike in discriminator training, \n",
    "        loss, acc = adversarial.train_on_batch(noise, y)\n",
    "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "        print(log)\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            # plot generator images on a periodic basis\n",
    "            plot_images(generator,\n",
    "                        noise_input=noise_input,\n",
    "                        show=False,\n",
    "                        step=(i + 1),\n",
    "                        model_name=model_name)\n",
    "   \n",
    "    # save the model after training the generator\n",
    "    # the trained generator can be reloaded for \n",
    "    # future MNIST digit generation\n",
    "    generator.save(model_name + \".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77fd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,\n",
    "                noise_input,\n",
    "                show=False,\n",
    "                step=0,\n",
    "                model_name=\"gan\"):\n",
    "    \n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict(noise_input)\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aada51",
   "metadata": {},
   "source": [
    "# build the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models():\n",
    "    # load MNIST dataset\n",
    "    (x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    image_size = x_train.shape[1]\n",
    "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "\n",
    "    model_name = \"dcgan_mnist\"\n",
    "    # network parameters\n",
    "    # the latent or z vector is 100-dim\n",
    "    latent_size = 100\n",
    "    batch_size = 64\n",
    "    train_steps = 40000\n",
    "    lr = 2e-4\n",
    "    decay = 6e-8\n",
    "    input_shape = (image_size, image_size, 1)\n",
    "\n",
    "    # build discriminator model\n",
    "    discriminator = Discriminator()\n",
    "    optimizer = RMSprop(lr=lr, decay=decay)\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # build generator model\n",
    "    generator = Generator()\n",
    "\n",
    "    # build adversarial model\n",
    "    optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\n",
    "    # freeze the weights of discriminator during adversarial training\n",
    "    discriminator.trainable = False\n",
    "    # adversarial = generator + discriminator\n",
    "    adversarial = Sequential([generator,discriminator ])\n",
    "    adversarial.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "    # train discriminator and adversarial networks\n",
    "    models = (generator, discriminator, adversarial)\n",
    "    params = (batch_size, latent_size, train_steps, model_name)\n",
    "    train(models, x_train, params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_and_train_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

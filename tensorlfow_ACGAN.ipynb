{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb709ff",
   "metadata": {},
   "source": [
    "# ACGAN => Auxiliary Classifier gan \n",
    "### this network is similar to the CGAN but instead of passing one hot label vector to both generator and discriminator we just pass it to the generator and give the discriminator another classification task to preform we will make the model classify the output and this belived to make the network learn better so we used this architecture \n",
    "\n",
    "![ACGAN](images/ACGAN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ae7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "from tensorflow.keras.layers import Dense , Conv2D ,concatenate, Conv2DTranspose , Flatten , Reshape  , BatchNormalization , Activation, Flatten ,LeakyReLU\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import mnist \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import math \n",
    "import os \n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d798a",
   "metadata": {},
   "source": [
    "# Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "774c7f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model) : \n",
    "    def __init__(self) : \n",
    "        super().__init__()  \n",
    "        self.dense_1 = Dense(7*7*128 ) \n",
    "        self.reshape = Reshape((7,7,128))\n",
    "\n",
    "        \n",
    "        self.sequential = Sequential([\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') , \n",
    "             Conv2DTranspose(128 , 5 , strides = 2 , padding = 'same') , \n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(64 , 5 , strides = 2  , padding = 'same') ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(32 , 5   , padding = 'same') ,\n",
    "             BatchNormalization() ,\n",
    "             Activation('relu') ,\n",
    "             Conv2DTranspose(1 , 5  , padding = 'same') , \n",
    "             Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "    def call(self , inputs ) :\n",
    "        X_vector , one_hot_vector = inputs\n",
    "        X = concatenate([X_vector , one_hot_vector] , axis = 1) \n",
    "        X = self.reshape(self.dense_1(X ))\n",
    "        return self.sequential(X)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fc3ec",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08330dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model) : \n",
    "    def __init__(self) : \n",
    "        super().__init__() \n",
    "        self.sequential = Sequential([\n",
    "            LeakyReLU(.2), \n",
    "            Conv2D(32 , 5 , padding ='same' , strides = 2) , \n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(64 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(128 , 5 , padding ='same' , strides = 2) ,\n",
    "            LeakyReLU(.2),\n",
    "            Conv2D(256 , 5 , padding ='same'  ) ,\n",
    "            Flatten() , \n",
    "        ])\n",
    "        self.output_1 = Dense(1 , activation ='sigmoid') \n",
    "        self.output_2 = Dense(10 , activation ='softmax' )\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def call(self, inputs ) : \n",
    "        X =  self.sequential(inputs) \n",
    "        output_1 = self.output_1(X) \n",
    "        output_2 = self.output_2(X) \n",
    "        return output_1 , output_2 \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4c8cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images , labels , generator , discriminator  , loss_fn_1 , loss_fn_2 , gen_optimizer , dis_optimizer):\n",
    "    noise = tf.random.normal([64, 100])\n",
    "    fake_labels = np.eye(10)[np.random.choice(10,64)]\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator((noise , fake_labels), training=True)\n",
    "\n",
    "        real_output_1 ,  real_output_2 = discriminator((images  ) , training=True)\n",
    "        fake_output_1 , fake_output_2 = discriminator((generated_images ) , training=True)\n",
    "\n",
    "        gen_loss_1 = loss_fn_1(fake_output_1 , tf.ones_like(fake_output_1))\n",
    "        gen_loss_2 = loss_fn_2(fake_output_2 , fake_labels )\n",
    "        gen_loss_2 = tf.cast(gen_loss_2, tf.float32)\n",
    "        gen_loss = gen_loss_1 +  gen_loss_2\n",
    "        \n",
    "        disc_real_loss_1 = loss_fn_1(real_output_1, tf.ones_like(real_output_1)) \n",
    "        disc_fake_loss_1 = loss_fn_1(fake_output_1 , tf.zeros_like(fake_output_1))\n",
    "        disc_real_loss_2 = loss_fn_2(real_output_2, labels ) \n",
    "        disc_fake_loss_2 = loss_fn_2(fake_output_2 , fake_labels)\n",
    "        disc_fake_loss_2 = tf.cast(disc_fake_loss_2 , tf.float32)\n",
    "        disc_loss = (disc_real_loss_1 + disc_fake_loss_1) + (disc_real_loss_2 + disc_fake_loss_2)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    return gen_loss , disc_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2596a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,\n",
    "                noise_input,\n",
    "                noise_class,\n",
    "                show=False,\n",
    "                step=0,\n",
    "                model_name=\"gan\"):\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict([noise_input, noise_class])\n",
    "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd255bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models(epochs):\n",
    "    # load MNIST dataset\n",
    "    (x_train, y_train ), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    x_train = np.reshape(x_train, [-1, 28, 28, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    y_train = tf.keras.utils.to_categorical(y_train , 10)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x_train , y_train) ) \n",
    "    ds = ds.shuffle(6000).batch(64)\n",
    "    ds = ds.take(500)\n",
    "\n",
    "    noise_class = np.eye(10)[np.arange(0, 16) % 10]\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "    categorical_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    # build discriminator model\n",
    "    discriminator = Discriminator()\n",
    "    # build generator model\n",
    "    generator = Generator()\n",
    "    \n",
    "    for epoch in range(epochs) : \n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "        for batch_images , labels  in ds : \n",
    "            gen_loss , dis_loss =  train_step(images = batch_images , labels = labels , generator = generator  , discriminator = discriminator\n",
    "            , loss_fn_1 =cross_entropy , loss_fn_2 = categorical_loss , gen_optimizer = generator_optimizer , dis_optimizer =discriminator_optimizer )\n",
    "            gen_losses.append(gen_loss) \n",
    "            dis_losses.append(dis_loss)\n",
    "        plot_images(generator ,tf.random.normal([16, 100]), noise_class , step = epoch  )\n",
    "        print(f'gen_loss : {np.mean(gen_losses)} , dis_Loss : {np.mean(dis_losses)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea532f50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 12:30:42.385383: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-16 12:30:42.524213: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 320ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 13.751045227050781 , dis_Loss : 27.290725708007812\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 1.6227505207061768 , dis_Loss : 20.044973373413086\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 1.6559436321258545 , dis_Loss : 19.80335235595703\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 0.22876526415348053 , dis_Loss : 17.400470733642578\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 0.007297718897461891 , dis_Loss : 16.738245010375977\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 0.003183717140927911 , dis_Loss : 16.545730590820312\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "gan  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
      "gen_loss : 0.0036967420019209385 , dis_Loss : 16.41858673095703\n"
     ]
    }
   ],
   "source": [
    "build_and_train_models(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8f5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
